{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_code.utilities import create_model\n",
    "from models_code.utilities import dump_results\n",
    "\n",
    "from models_code.experiments import correlation_test_error_uncertainty\n",
    "from models_code.experiments import correlation_test_error_uncertainty_variational\n",
    "from models_code.experiments import load_lfw\n",
    "from models_code.experiments import not_mnist_predictions\n",
    "from models_code.experiments import not_mnist_prediction_variational\n",
    "from models_code.experiments import prediction_variational\n",
    "from models_code.experiments import non_distribution\n",
    "from models_code.experiments import test_eval\n",
    "from models_code.experiments import test_eval_variational\n",
    "from models_code.experiments import softmax\n",
    "from models_code.experiments import softmax2d\n",
    "\n",
    "from models_code.mnist import perform_training\n",
    "from models_code.mnist import MonteCarloDropout\n",
    "\n",
    "from models_code.cifar import load_data\n",
    "from models_code.cifar import load_svhn\n",
    "from models_code.cifar import Cifar\n",
    "from models_code.cifar import MCCifar\n",
    "from models_code.cifar import ISCifar\n",
    "\n",
    "from models_code.bayesbybackprop import BBPMnist\n",
    "from models_code.bayesbybackprop import BBPCifar\n",
    "from models_code.bayesbybackprop import train_bbp\n",
    "from models_code.bayesbybackprop import test_bbp\n",
    "\n",
    "from models_code.utilities import load_model\n",
    "\n",
    "from utilities.metric import predictive_entropy\n",
    "from utilities.metric import entropy\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_same_seed():\n",
    "    torch.manual_seed(9)\n",
    "    torch.cuda.manual_seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "log_interval = 100\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard, optimizer, cross_entropy  = create_model(Cifar)\n",
    "\n",
    "# perform_training(\n",
    "#     epochs,\n",
    "#     standard,\n",
    "#     train_loader,\n",
    "#     test_loader,\n",
    "#     optimizer,\n",
    "#     cross_entropy,\n",
    "#     log_interval,\n",
    "#     './models/cifar_lenet/standard.torch',\n",
    "#     60000 // batch_size + 1,\n",
    "#     channels=3\n",
    "# )\n",
    "\n",
    "standard = load_model(Cifar, './models/cifar_lenet/standard.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First experiments - test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels, test_probs = test_eval(standard, test_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels, softmax(test_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment  - test error vs uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty(\n",
    "    lambda x: entropy(x),\n",
    "    softmax2d(test_probs),\n",
    "    test_labels\n",
    ")\n",
    "\n",
    "# roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty(\n",
    "#     lambda x: -np.max(x, axis=1),\n",
    "#     softmax2d(test_probs),\n",
    "#     test_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/cifar/standard.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment - CIFAR vs SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_loader = load_svhn(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_preds, svhn_labels, svhn_probs = test_eval(standard, svhn_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "#     test_probs,\n",
    "#     entropy(softmax(test_probs)).reshape(10000,1),\n",
    "#     entropy(softmax(svhn_probs)).reshape(73257,1),\n",
    "#     83257,\n",
    "#     10000\n",
    "# )\n",
    "\n",
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    np.max(softmax(test_probs), axis=1).reshape(10000,1),\n",
    "    np.max(softmax(svhn_probs), axis=1).reshape(73257,1),\n",
    "    83257,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/svhn/standard.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar vs LFW-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_loader = load_lfw(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_preds, lfw_labels, lfw_probs = test_eval(standard, lfw_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    entropy(softmax(test_probs)).reshape(10000,1),\n",
    "    entropy(softmax(lfw_probs)).reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")\n",
    "\n",
    "print(roc)\n",
    "print(ac)\n",
    "\n",
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    np.max(softmax(test_probs), axis=1).reshape(10000,1),\n",
    "    np.max(softmax(lfw_probs), axis=1).reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size, shuffle=False)\n",
    "svhn_loader = load_svhn(batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "test_labels_all = []\n",
    "test_probs_all = []\n",
    "svhn_labels_all = []\n",
    "svhn_probs_all = []\n",
    "lfw_labels_all = []\n",
    "lfw_probs_all = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    de = load_model(Cifar, './models/cifar_lenet/de{}.torch'.format(i))\n",
    "    torch.cuda.empty_cache()\n",
    "    test_preds, test_labels, test_probs = test_eval(de, test_loader, channels=3)\n",
    "    \n",
    "    test_probs_all.append(test_probs)\n",
    "    \n",
    "    if i == 4:\n",
    "        test_labels_all = test_labels\n",
    "    \n",
    "# svhn predictions\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    de = load_model(Cifar, './models/cifar_lenet/de{}.torch'.format(i))\n",
    "    torch.cuda.empty_cache()\n",
    "    svhn_preds, svhn_labels, svhn_probs = test_eval(de, svhn_loader, channels=3)\n",
    "    \n",
    "    svhn_probs_all.append(svhn_probs)\n",
    "    \n",
    "    if i == 4:\n",
    "        svhn_labels_all = svhn_labels\n",
    "        \n",
    "# lfw predictions\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    de = load_model(Cifar, './models/cifar_lenet/de{}.torch'.format(i))\n",
    "    torch.cuda.empty_cache()\n",
    "    lfw_preds, lfw_labels, lfw_probs = test_eval(de, lfw_loader, channels=3)\n",
    "    \n",
    "    lfw_probs_all.append(lfw_probs)\n",
    "    \n",
    "    if i == 4:\n",
    "        lfw_labels_all = lfw_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First experiments - test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_stacked = np.stack([softmax2d(sample) for sample in test_probs_all])\n",
    "svhn_probs_stacked = np.stack([softmax2d(sample) for sample in svhn_probs_all])\n",
    "lfw_probs_stacked = np.stack([softmax2d(sample) for sample in lfw_probs_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels_all, np.argmax(np.mean(test_probs_stacked, axis=0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels_all, np.mean(test_probs_stacked, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment  - test error vs uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty_variational(\n",
    "    predictive_entropy,\n",
    "    test_probs_stacked,\n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/cifar/de.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment - CIFAR vs SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_probs_stacked).reshape(10000,1),\n",
    "    predictive_entropy(svhn_probs_stacked).reshape(73257,1),\n",
    "    83257,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/svhn/de.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_probs_stacked).reshape(10000,1),\n",
    "    predictive_entropy(lfw_probs_stacked).reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc, optimizer, cross_entropy  = create_model(MCCifar)\n",
    "\n",
    "# perform_training(\n",
    "#     epochs + 50,\n",
    "#     mc,\n",
    "#     train_loader,\n",
    "#     test_loader,\n",
    "#     optimizer,\n",
    "#     cross_entropy,\n",
    "#     log_interval,\n",
    "#     './models/cifar_lenet/mc.torch',\n",
    "#     60000 // batch_size + 1,\n",
    "#     channels=3\n",
    "# )\n",
    "\n",
    "mc = load_model(Cifar, './models/cifar_lenet/mc.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.dropout2 = MonteCarloDropout(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_preds = test_eval_variational(mc, test_loader, 50, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels, np.argmax(np.mean(test_preds, axis=0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels, np.mean(test_preds, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty_variational(\n",
    "    predictive_entropy,\n",
    "    test_preds,\n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/cifar/mc.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_loader = load_svhn(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnist_labels, notmnist_probs, notmnist_images = prediction_variational(mc, svhn_loader, 50,\n",
    "                                                                                    channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_preds).reshape(10000,1),\n",
    "    predictive_entropy(notmnist_probs).reshape(73257,1),\n",
    "    83257,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/svhn/mc.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFW-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_loader = load_lfw(batch_size)\n",
    "\n",
    "lfw_labels, lfw_probs, lfw_images = prediction_variational(mc, lfw_loader, 50, channels=3)\n",
    "\n",
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_preds).reshape(10000,1),\n",
    "    predictive_entropy(lfw_probs).reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes by Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbp, optimizer, cross_entropy  = create_model(BBPCifar)\n",
    "\n",
    "\n",
    "# for epoch in range(1, epochs):\n",
    "#     train_bbp(\n",
    "#         bbp,\n",
    "#         optimizer,\n",
    "#         train_loader,\n",
    "#         cross_entropy,\n",
    "#         batch_size,\n",
    "#         log_interval,\n",
    "#         60000 // batch_size + 1,\n",
    "#         epoch,\n",
    "#         channels=3\n",
    "#     )\n",
    "#     test_bbp(\n",
    "#         bbp,\n",
    "#         test_loader,\n",
    "#         cross_entropy,\n",
    "#         batch_size,\n",
    "#         epoch,\n",
    "#         channels=3\n",
    "#     )\n",
    "\n",
    "\n",
    "bbp = load_model(BBPCifar, './models/cifar_lenet/bbp.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(bbp.state_dict(), './models/cifar_lenet/bbp02.torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_preds = test_eval_variational(bbp, test_loader, 10, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels, np.argmax(np.mean(test_preds, axis=0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels, np.mean(test_preds, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty_variational(\n",
    "    predictive_entropy,\n",
    "    test_preds,\n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/cifar/bbp.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_loader = load_svhn(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnist_labels, notmnist_probs, notmnist_images = prediction_variational(bbp, svhn_loader, 10,\n",
    "                                                                                    channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_preds).reshape(10000,1),\n",
    "    predictive_entropy(notmnist_probs).reshape(73257,1),\n",
    "    83257,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/svhn/bbp.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_loader = load_lfw(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_labels, lfw_probs, lfw_images = prediction_variational(bbp, lfw_loader, 10, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_preds,\n",
    "    predictive_entropy(test_preds).reshape(10000,1),\n",
    "    predictive_entropy(lfw_probs).reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhibited softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_, optimizer, cross_entropy  = create_model(ISCifar)\n",
    "\n",
    "def is_loss(model):\n",
    "    \n",
    "    return (\n",
    "        lambda pred,y: cross_entropy(pred,y)\n",
    "        + 0.01 * (model.dense3.weight.data ** 2).sum()\n",
    "        + 0.000001 * pred.sum()\n",
    "    )\n",
    "\n",
    "perform_training(\n",
    "    epochs,\n",
    "    is_,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    is_loss(is_),\n",
    "    log_interval,\n",
    "    './models/cifar_lenet/is2.torch',\n",
    "    60000 // batch_size + 1,\n",
    "    channels=3\n",
    ")\n",
    "\n",
    "# is_ = load_model(ISCifar, './models/cifar_lenet/is.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels, test_probs = test_eval(is_, test_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels, softmax2d(test_probs[:,:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty(\n",
    "    lambda x: softmax2d(x)[:,10],\n",
    "    test_probs,\n",
    "    test_labels\n",
    ")\n",
    "\n",
    "# roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty(\n",
    "#     lambda x: entropy(softmax2d(x)[:,:10]),\n",
    "#     test_probs,\n",
    "#     test_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/mnist/is.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_loader = load_svhn(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_preds, svhn_labels, svhn_probs = test_eval(is_, svhn_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    softmax2d(test_probs)[:,10].reshape(10000,1),\n",
    "    softmax2d(svhn_probs)[:,10].reshape(73257,1),\n",
    "    83257,\n",
    "    10000\n",
    ")\n",
    "\n",
    "# roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "#     test_probs,\n",
    "#     entropy(softmax2d(test_probs[:,:10])).reshape(10000,1),\n",
    "#     entropy(softmax2d(svhn_probs[:,:10])).reshape(73257,1),\n",
    "#     83257,\n",
    "#     10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/notmnist/is.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFW-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_loader = load_lfw(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_preds, lfw_labels, lfw_probs = test_eval(is_, lfw_loader, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    softmax2d(test_probs)[:,10].reshape(10000,1),\n",
    "    softmax2d(lfw_probs)[:,10].reshape(1054,1),\n",
    "    11054,\n",
    "    10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
