{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_code.utilities import load_model\n",
    "from models_code.experiments import softmax\n",
    "from models_code.experiments import softmax2d_ensemble\n",
    "from models_code.experiments import test_eval\n",
    "from models_code.experiments import not_mnist_predictions\n",
    "from models_code.experiments import load_omniglot\n",
    "from models_code.experiments import load_cifar_bw\n",
    "from models_code.experiments import load_notmnist\n",
    "from models_code.experiments import non_distribution\n",
    "from models_code.mnist import Mnist\n",
    "from models_code.mnist import train\n",
    "from models_code.mnist import test\n",
    "from utilities.metric import predictive_entropy\n",
    "from models_code.experiments import correlation_test_error_uncertainty_variational\n",
    "\n",
    "\n",
    "from models_code.utilities import dump_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "log_interval = 100\n",
    "epochs = 12\n",
    "num_batches = 60000 / 128\n",
    "\n",
    "torch.manual_seed(9)\n",
    "torch.cuda.manual_seed(9)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(2),\n",
    "                       transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(2),\n",
    "                       transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Mnist().cuda() for i in range(5)]\n",
    "optimizers = [optim.Adadelta(model.parameters()) for model in models]\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(epochs):\n",
    "#     for model_index in range(5):\n",
    "#         train(i, models[model_index], train_loader, optimizers[model_index], loss_function, log_interval, num_batches)\n",
    "#         test(i, models[model_index], test_loader, optimizers[model_index], loss_function, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(models[0].state_dict(), 'models/mnist_lenet/de1.torch')\n",
    "# torch.save(models[1].state_dict(), 'models/mnist_lenet/de2.torch')\n",
    "# torch.save(models[2].state_dict(), 'models/mnist_lenet/de3.torch')\n",
    "# torch.save(models[3].state_dict(), 'models/mnist_lenet/de4.torch')\n",
    "# torch.save(models[4].state_dict(), 'models/mnist_lenet/de5.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    models[i] = load_model(Mnist, 'models/mnist_lenet/de{}.torch'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy and NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds1, test_labels1, test_probs1 = test_eval(models[0], test_loader)\n",
    "test_preds2, test_labels2, test_probs2 = test_eval(models[1], test_loader)\n",
    "test_preds3, test_labels3, test_probs3 = test_eval(models[2], test_loader)\n",
    "test_preds4, test_labels4, test_probs4 = test_eval(models[3], test_loader)\n",
    "test_preds5, test_labels5, test_probs5 = test_eval(models[4], test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = np.stack([test_probs1, test_probs2, test_probs3, test_probs4, test_probs5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels1, np.argmax(np.mean(test_probs, axis=0), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_labels1, softmax(np.mean(test_probs, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omniglot experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot_loader = load_omniglot(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot_truth, omniglot_probs, omniglot_images = not_mnist_predictions([\n",
    "    models[0],\n",
    "    models[1],\n",
    "    models[2],\n",
    "    models[3],\n",
    "    models[4]\n",
    "], omniglot_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    predictive_entropy(softmax2d_ensemble(test_probs)).reshape(10000,1),\n",
    "    predictive_entropy(omniglot_probs).reshape(32460,1),\n",
    "    42460,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar-bw experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_loader = load_cifar_bw(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_truth, cifar_probs, cifar_images = not_mnist_predictions([\n",
    "    models[0],\n",
    "    models[1],\n",
    "    models[2],\n",
    "    models[3],\n",
    "    models[4]\n",
    "], cifar_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    predictive_entropy(softmax2d_ensemble(test_probs)).reshape(10000,1),\n",
    "    predictive_entropy(cifar_probs).reshape(50000,1),\n",
    "    60000,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnist_loader = load_notmnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmnist_truth, notmnist_probs, notmnist_images = not_mnist_predictions([\n",
    "    models[0],\n",
    "    models[1],\n",
    "    models[2],\n",
    "    models[3],\n",
    "    models[4]\n",
    "], notmnist_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    predictive_entropy(softmax2d_ensemble(test_probs)).reshape(10000,1),\n",
    "    predictive_entropy(notmnist_probs).reshape(18724,1),\n",
    "    28724,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test error vs uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty_variational(\n",
    "    predictive_entropy,\n",
    "    softmax2d_ensemble(test_probs),\n",
    "    test_labels1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
