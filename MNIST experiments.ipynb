{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models_code.utilities import create_model\n",
    "from models_code.utilities import dump_results\n",
    "\n",
    "from models_code.experiments import correlation_test_error_uncertainty\n",
    "from models_code.experiments import load_notmnist\n",
    "from models_code.experiments import load_omniglot\n",
    "from models_code.experiments import load_cifar_bw\n",
    "\n",
    "from models_code.experiments import not_mnist_predictions\n",
    "from models_code.experiments import non_distribution\n",
    "from models_code.experiments import test_eval\n",
    "from models_code.experiments import softmax2d\n",
    "\n",
    "from models_code.mnist import perform_training\n",
    "from models_code.mnist import load_data\n",
    "from models_code.mnist import test\n",
    "\n",
    "from models_code.mnist import Mnist\n",
    "from models_code.mnist import ISMnist\n",
    "from models_code.mnist import DeVriesMnist\n",
    "\n",
    "from models_code.utilities import load_model\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_same_seed():\n",
    "    torch.manual_seed(9)\n",
    "    torch.cuda.manual_seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "log_interval = 100\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeVries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.nn.functional import dropout\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def encode_onehot(labels, n_classes):\n",
    "    onehot = torch.FloatTensor(labels.size()[0], n_classes)\n",
    "    labels = labels.data\n",
    "    if labels.is_cuda:\n",
    "        onehot = onehot.cuda()\n",
    "    onehot.zero_()\n",
    "    onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_devries(\n",
    "        lmbda,\n",
    "        epoch,\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        loss_function,\n",
    "        log_interval,\n",
    "        num_batches,\n",
    "        channels=1\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        data = torch.autograd.Variable(data)\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        y_, confidence =  model(data.view(-1, channels, 32, 32))\n",
    "        pred_original = torch.softmax(y_, dim=-1)\n",
    "        confidence = torch.sigmoid(confidence)\n",
    "        labels_onehot = torch.autograd.Variable(encode_onehot(y, 10)).cuda()\n",
    "\n",
    "        eps = 1e-12\n",
    "        pred_original = torch.clamp(pred_original, 0. + eps, 1. - eps)\n",
    "        confidence = torch.clamp(confidence, 0. + eps, 1. - eps)\n",
    "\n",
    "        b = torch.autograd.Variable(torch.bernoulli(torch.Tensor(confidence.size()).uniform_(0, 1))).cuda()\n",
    "        conf = confidence * b + (1 - b)\n",
    "        pred_new = pred_original * conf.expand_as(pred_original) + labels_onehot * (1 - conf.expand_as(labels_onehot))\n",
    "        pred_new = torch.log(pred_new)\n",
    "        \n",
    "        xentropy_loss = loss_function(pred_new, torch.autograd.Variable(y).cuda())\n",
    "        confidence_loss = torch.mean(-torch.log(confidence))\n",
    "        \n",
    "        total_loss = xentropy_loss + (lmbda * confidence_loss)\n",
    "\n",
    "#         if 0.001 > confidence_loss.item() :\n",
    "#             lmbda = lmbda / 1.01\n",
    "#         elif 0.001 <= confidence_loss.item() :\n",
    "#             lmbda = lmbda / 0.99\n",
    "\n",
    "        total_loss.backward()\n",
    "        train_loss += total_loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy += accuracy_score(y, np.argmax(pred_original.cpu().data.numpy(), axis=1))\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader),\n",
    "                       total_loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f} Average accuracy: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset), accuracy / num_batches))\n",
    "    print(lmbda)\n",
    "    return lmbda\n",
    "\n",
    "def test(\n",
    "        epoch,\n",
    "        model,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        loss_function,\n",
    "        log_interval,\n",
    "        channels=1\n",
    "):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    y_s = []\n",
    "    ys = []\n",
    "    softmax = nn.Softmax()\n",
    "    for i, (data, y) in enumerate(test_loader):\n",
    "        data = data.cuda()\n",
    "        data = Variable(data)\n",
    "        y_, aft_cauchy = model(data.view(-1, channels, 32, 32))\n",
    "        y_s.append(softmax(y_).cpu().data.numpy())\n",
    "        ys.append(y)\n",
    "\n",
    "        test_loss += loss_function(y_, Variable(y).cuda()).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "    print('Test accuracy: {}'.format(accuracy_score(\n",
    "        np.concatenate(ys),\n",
    "        np.argmax(np.concatenate(y_s), axis=1)\n",
    "    )))\n",
    "    \n",
    "def perform_training_devries(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    log_interval,\n",
    "    savepath,\n",
    "    num_batches,\n",
    "    channels=1\n",
    "):\n",
    "    lmbd = 0.001\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        lmbd = train_devries(\n",
    "            lmbd,\n",
    "            epoch,\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            loss_function,\n",
    "            log_interval,\n",
    "            num_batches,\n",
    "            channels\n",
    "        )\n",
    "        test(\n",
    "            epoch,\n",
    "            model,\n",
    "            test_loader,\n",
    "            optimizer,\n",
    "            loss_function,\n",
    "            log_interval,\n",
    "            channels\n",
    "        )\n",
    "    torch.save(model.state_dict(), savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_same_seed()\n",
    "train_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.010391\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.001846\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.000740\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.000465\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.000696\n",
      "====> Epoch: 1 Average loss: 0.0019 Average accuracy: 0.8408\n",
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msusik/.virtualenvs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: -0.0770\n",
      "Test accuracy: 0.9711\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000836\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.000265\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.000247\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.000327\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.000178\n",
      "====> Epoch: 2 Average loss: 0.0004 Average accuracy: 0.9739\n",
      "0.001\n",
      "====> Test set loss: -0.0722\n",
      "Test accuracy: 0.9814\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.000356\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000138\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.000411\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000204\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000071\n",
      "====> Epoch: 3 Average loss: 0.0003 Average accuracy: 0.9809\n",
      "0.001\n",
      "====> Test set loss: -0.0881\n",
      "Test accuracy: 0.9836\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000100\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000133\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000046\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000657\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000324\n",
      "====> Epoch: 4 Average loss: 0.0002 Average accuracy: 0.9847\n",
      "0.001\n",
      "====> Test set loss: -0.0725\n",
      "Test accuracy: 0.9864\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000149\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000078\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.000208\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000104\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000201\n",
      "====> Epoch: 5 Average loss: 0.0002 Average accuracy: 0.9871\n",
      "0.001\n",
      "====> Test set loss: -0.0784\n",
      "Test accuracy: 0.9885\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000125\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000393\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000163\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000170\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000037\n",
      "====> Epoch: 6 Average loss: 0.0002 Average accuracy: 0.9890\n",
      "0.001\n",
      "====> Test set loss: -0.0765\n",
      "Test accuracy: 0.9871\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000026\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000017\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000041\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000056\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000146\n",
      "====> Epoch: 7 Average loss: 0.0001 Average accuracy: 0.9906\n",
      "0.001\n",
      "====> Test set loss: -0.0734\n",
      "Test accuracy: 0.9903\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000025\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000088\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000158\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000038\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000355\n",
      "====> Epoch: 8 Average loss: 0.0001 Average accuracy: 0.9916\n",
      "0.001\n",
      "====> Test set loss: -0.0693\n",
      "Test accuracy: 0.9758\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000066\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000097\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000008\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000074\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000065\n",
      "====> Epoch: 9 Average loss: 0.0001 Average accuracy: 0.9925\n",
      "0.001\n",
      "====> Test set loss: -0.0755\n",
      "Test accuracy: 0.9901\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000257\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000022\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000014\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000010\n",
      "====> Epoch: 10 Average loss: 0.0001 Average accuracy: 0.9933\n",
      "0.001\n",
      "====> Test set loss: -0.0766\n",
      "Test accuracy: 0.9877\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000107\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.000113\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.000037\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000054\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.000074\n",
      "====> Epoch: 11 Average loss: 0.0001 Average accuracy: 0.9939\n",
      "0.001\n",
      "====> Test set loss: -0.0783\n",
      "Test accuracy: 0.9897\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000066\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.000407\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.000138\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000019\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000012\n",
      "====> Epoch: 12 Average loss: 0.0001 Average accuracy: 0.9943\n",
      "0.001\n",
      "====> Test set loss: -0.0757\n",
      "Test accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "dv, optimizer, nll  = create_model(DeVriesMnist, loss_function=torch.nn.NLLLoss)\n",
    "\n",
    "perform_training_devries(\n",
    "    epochs,\n",
    "    dv,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    nll,\n",
    "    log_interval,\n",
    "    './models/mnist_lenet/dv.torch',\n",
    "    60000 // batch_size + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels, test_probs = test_eval(dv, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03794622704798509"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_labels, softmax2d(test_probs[:,:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval_confidence(\n",
    "        model,\n",
    "        test_loader,\n",
    "        channels=1,\n",
    "        num_classes=10,\n",
    "        sentiment=False,\n",
    "        is_sentiment=False,\n",
    "        size_factor=1\n",
    "):\n",
    "    model.eval()\n",
    "    all_results = []\n",
    "    groundtruth = []\n",
    "    probs = []\n",
    "    for i, (data, y) in enumerate(test_loader):\n",
    "        data = data.cuda()\n",
    "        data = Variable(data)\n",
    "        if not sentiment and not is_sentiment:\n",
    "            y_, sec_ = model(data.view(-1, channels, 32*size_factor, 32*size_factor))\n",
    "        else:\n",
    "            y_, sec_ = model(data.view(-1, 400))\n",
    "        all_results.append(\n",
    "            y_.cpu().data.numpy()[:, :num_classes].argmax(axis=1)\n",
    "        )\n",
    "        probs.append(sec_.cpu().data.numpy())\n",
    "        groundtruth.append(y.cpu().numpy())\n",
    "\n",
    "    if sentiment:\n",
    "        return (\n",
    "            sigmoid(np.concatenate(probs)),\n",
    "            np.concatenate(groundtruth),\n",
    "            np.concatenate(probs)\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        np.concatenate(all_results),\n",
    "        np.concatenate(groundtruth),\n",
    "        np.concatenate(probs)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def not_mnist_predictions_confidence(models, not_mnist_loader, softmaxed=True):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    y_truth = []\n",
    "    probs = []\n",
    "    images = []\n",
    "    softmax = torch.nn.Softmax()\n",
    "\n",
    "    for i, (data, y) in enumerate(not_mnist_loader):\n",
    "        images.append(data.cpu().numpy())\n",
    "        y_s = []\n",
    "        data = data.cuda()\n",
    "        data = Variable(data)\n",
    "\n",
    "        for model_ in models:\n",
    "            output_, q = model_(data[:, 0, :, :].view(-1, 1, 32, 32))\n",
    "            if softmaxed:\n",
    "                y_ = softmax(q)\n",
    "            else:\n",
    "                y_ = q\n",
    "            y_s.append(y_.cpu().data.numpy())\n",
    "        y_truth.append(y.cpu().numpy())\n",
    "        probs.append(np.stack(y_s))\n",
    "\n",
    "    return (\n",
    "        np.concatenate(y_truth),\n",
    "        np.concatenate(probs, axis=1),\n",
    "        images\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels, confidence = test_eval_confidence(dv, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5595111],\n",
       "       [6.019532 ],\n",
       "       [0.3754807],\n",
       "       ...,\n",
       "       [1.7956295],\n",
       "       [1.7851479],\n",
       "       [2.2041385]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second experiment - wrong prediction detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = correlation_test_error_uncertainty(\n",
    "    lambda x: -x,\n",
    "    confidence,\n",
    "    test_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5595514502918684"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179734007698973"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/mnist/dv.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third experiment - out of distribution detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_mnist_loader = load_notmnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notmnist_truth, notmnist_confidence, notmnist_images = not_mnist_predictions_confidence([dv], not_mnist_loader, softmaxed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_distribution(test_entropies, other_entropies, num_all, num_test):\n",
    "    disting = np.concatenate([test_entropies, other_entropies])\n",
    "    target = np.zeros(num_all, dtype=np.int)\n",
    "    target[num_test:] = 1\n",
    "\n",
    "    roc = roc_auc_score(target, disting)\n",
    "    ap = average_precision_score(target, disting)\n",
    "    fpr, tpr, _ = roc_curve(target, disting)\n",
    "    pr, re, _ = precision_recall_curve(target, disting)\n",
    "\n",
    "    return roc, ap, fpr, tpr, pr, re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 763., 2042., 5496., 4687., 2718., 1730.,  873.,  339.,   68.,\n",
       "           8.]),\n",
       " array([-0.14230931,  2.660894  ,  5.464097  ,  8.267301  , 11.070503  ,\n",
       "        13.873707  , 16.67691   , 19.480114  , 22.283316  , 25.08652   ,\n",
       "        27.889723  ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(confidence, alpha=0.5)\n",
    "plt.hist(notmnist_confidence[0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    -confidence,\n",
    "    -notmnist_confidence[0],\n",
    "    28724,\n",
    "    10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7700017918179876"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526299462487923"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/notmnist/is.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_mnist_loader = load_omniglot(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notmnist_truth, notmnist_probs, notmnist_images = not_mnist_predictions([is_], not_mnist_loader, softmaxed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    softmax2d(test_probs)[:,10].reshape(10000,1),\n",
    "    softmax2d(notmnist_probs[0])[:,10].reshape(32460,1),\n",
    "    42460,\n",
    "    10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/omniglot/is.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar-bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_mnist_loader = load_cifar_bw(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notmnist_truth, notmnist_probs, notmnist_images = not_mnist_predictions([is_], not_mnist_loader, softmaxed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc, ac, fpr, tpr, pr, re = non_distribution(\n",
    "    test_probs,\n",
    "    softmax2d(test_probs)[:,10].reshape(10000,1),\n",
    "    softmax2d(notmnist_probs[0])[:,10].reshape(50000,1),\n",
    "    60000,\n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_results(fpr, tpr, pr, re, './results/cifar-bw/is.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
